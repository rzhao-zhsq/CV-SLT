task: S2T
data:
    translate: true
    dataset_name: csl-daily
    input_data: videos
    input_streams:
        - rgb

    train: data/csl-daily/csl-daily.train
    dev: data/csl-daily/csl-daily.dev
    test: data/csl-daily/csl-daily.test

#    dev_head_rgb_input:   data/csl-daily_s2g/extract_features/head_rgb_input/dev.pkl
#    test_head_rgb_input:  data/csl-daily_s2g/extract_features/head_rgb_input/test.pkl
#    train_head_rgb_input: data/csl-daily_s2g/extract_features/head_rgb_input/train.pkl
    dev_head_rgb_input:   /home/rzhao/data/slt/tsn/SingleStream/csl-daily_s2g/extract_features/head_rgb_input/dev.pkl
    test_head_rgb_input:  /home/rzhao/data/slt/tsn/SingleStream/csl-daily_s2g/extract_features/head_rgb_input/test.pkl
    train_head_rgb_input: /home/rzhao/data/slt/tsn/SingleStream/csl-daily_s2g/extract_features/head_rgb_input/train.pkl

    level: char
    max_sent_length: 400
    txt_lowercase: true
testing:
    cfg:
        recognition:
            beam_size: 1
        translation:
            length_penalty: 1
            max_length: 500
            num_beams: 5
training:
    batch_size: 16
    keep_last_ckpts: 2
    model_dir: /home/rzhao/python/vtsnr/experiments/outputs/GridSearch/csl-daily_vs2t_kl3_postfix_dim64_residual_attention_1e-4_1e-4_5e-6_seed15*
    amp: True
    num_workers: 4
    optimization:
        betas:
            - 0.9
            - 0.998
        learning_rate:
            default: 0.0001
            translation: 1.0e-05
        optimizer: Adam
        scheduler: cosineannealing
        t_max: 40
        weight_decay: 0.001
    overwrite: true
    random_seed: 0
    shuffle: true
    total_epoch: 40
    validation:
        cfg:
            recognition:
                beam_size: 1
            translation:
                length_penalty: 1
                max_length: 60
                num_beams: 5
        freq: 1
        unit: epoch
        valid_start_step: 0
        valid_start_epoch: 0
model:
    mode: variational
    recognition_weight: 0.0
    translation_weight: 1.0
    RecognitionNetwork:
        freeze: false
        GlossTokenizer:
            gloss2id_file: data/csl-daily/gloss2ids.pkl
        fuse_method: empty
        gloss_feature_ensemble: gloss_probabilities
        s3d:
            freeze_block: 1
            pretrained_ckpt: /home/rzhao/pretrained_models/slt/s3ds_glosscls_ckpt
            use_block: 4
        visual_head:
            freeze: false
#            pretrained_ckpt: pretrained_models/csl-daily_s2g/ckpts/best.ckpt
            pretrained_ckpt: /home/rzhao/python/tsn/experiments/official_ckpt/SingleStream/csl-daily_s2g/ckpts/best.ckpt
            ff_kernelsize:
                - 3
                - 3
            ff_size: 2048
            hidden_size: 512
            input_size: 832
            pe: true
    TranslationNetwork:
        GlossEmbedding:
#            gloss2embed_file: pretrained_models/mBart_zh/gloss_embeddings.bin
            gloss2embed_file: /home/rzhao/pretrained_models/slt/mBart_zh/gloss_embeddings.bin
        GlossTokenizer:
#            gloss2id_file: pretrained_models/mBart_zh/gloss2ids.pkl
            gloss2id_file: /home/rzhao/pretrained_models/slt/mBart_zh/gloss2ids.pkl
            src_lang: zh_CSL
        TextTokenizer:
#            pretrained_model_name_or_path: pretrained_models/mBart_zh
#            pruneids_file: pretrained_models/mBart_zh/old2new_vocab.pkl
            pretrained_model_name_or_path: /home/rzhao/pretrained_models/slt/mBart_zh
            pruneids_file: /home/rzhao/pretrained_models/slt/mBart_zh/old2new_vocab.pkl
            tgt_lang: zh_CN
        freeze_txt_embed: false
        label_smoothing: 0.2
        gls_eos: txt
        overwrite_cfg:
            attention_dropout: 0.1
            dropout: 0.3
        pretrained_model_name_or_path: /home/rzhao/pretrained_models/slt/mBart_zh
        load_ckpt: /home/rzhao/python/tsn/experiments/outputs/SingleStream/csl-daily_g2t_best/ckpts/best.ckpt

    VLMapper:
        freeze: false
        type: embedding
        multistream_fuse: empty

    VariationalNetwork:
        input_embed_dim: 1024
        latent_dim: 64
        attention_shared: True
        norm: postfix

        gkl_factor: 1.0
        gkl_start_ratio: 0.0
        gkl_warmup_start: 0
        gkl_warmup_step: 4000

        kl_factor: 1.0
        kl_start_ratio: 0.0
        kl_warmup_start: 0
        kl_warmup_step: 4000
